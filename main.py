#!/usr/bin/env python3
"""
Main script for CNN visual object classification on Stanford Cars dataset.

This script implements a complete pipeline for:
- Training a Compact CNN for car classification
- Evaluating model performance
- Analyzing hyperparameters
- Visualizing results

Usage:
    python main.py --mode train [--config config.yaml]
    python main.py --mode evaluate [--model_path models/best_model.pth]
    python main.py --mode hyperparameter_search [--max_experiments 10]
    python main.py --mode full_pipeline
"""

import argparse
import logging
import os
import sys
import torch
from datetime import datetime

# Add src directory to path
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from src.config_manager import ConfigManager
from src.model import create_model_from_config
from src.data_loader import create_data_loaders, create_train_val_loaders
from src.trainer import Trainer, DeviceManager
from src.evaluation import ModelEvaluator
from src.visualization import Visualizer
from src.hyperparameter_analysis import HyperparameterAnalyzer

def setup_logging(config):
    """Setup logging configuration."""
    log_level = config.get('logging.log_level', 'INFO')
    log_file = config.get('logging.log_file', 'logs/training.log')
    
    # Create logs directory
    os.makedirs(os.path.dirname(log_file), exist_ok=True)
    
    # Configure logging with simpler format for console
    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        format='%(message)s',  # Simplified format for console
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler(sys.stdout)
        ],
        force=True  # Override any existing config
    )
    
    return logging.getLogger(__name__)

def train_model(config, logger):
    """Train the CNN model."""
    import time
    training_start_time = time.time()
    
    print("\n" + "="*80)
    print("ðŸš€ STARTING CNN TRAINING")
    print("="*80)
    print(f"â° Start Time: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ðŸ“Š Dataset: {config.get('dataset.num_classes')} classes, {config.get('dataset.max_images_per_class')} images per class")
    print(f"ðŸŽ¯ Epochs: {config.get('training.epochs')}, Batch Size: {config.get('dataset.batch_size')}")
    print(f"ðŸ’» Device: {'GPU' if config.get('device.use_gpu') else 'CPU'}")
    print("="*80)
    
    logger.info("Starting model training...")
    
    # Create directories
    config.create_directories()
    
    # Setup device
    device = DeviceManager.get_device(config)
    logger.info(f"Using device: {device}")
    
    # Create data loaders
    train_loader, val_loader, class_to_idx = create_train_val_loaders(config)
    logger.info(f"Created data loaders with {len(class_to_idx)} classes")
    
    # Create model
    model = create_model_from_config(config)
    logger.info(f"Created model: {model.__class__.__name__}")
    logger.info(model.model_summary())
    
    # Create trainer
    trainer = Trainer(model, config, device)
    
    # Train model
    history = trainer.train(train_loader, val_loader)
    
    # Save best model
    if config.get('logging.save_model', True):
        model_save_dir = config.get('logging.model_save_dir', 'models')
        model_path = os.path.join(model_save_dir, 'best_model.pth')
        trainer.save_model(model_path, save_best=True)
        logger.info(f"Best model saved to {model_path}")
    
    training_end_time = time.time()
    total_training_time = training_end_time - training_start_time
    
    print("\n" + "="*80)
    print("ðŸŽ‰ TRAINING COMPLETED!")
    print("="*80)
    print(f"â° End Time: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"â±ï¸  Total Training Time: {total_training_time:.2f} seconds ({total_training_time/60:.1f} minutes)")
    print(f"ðŸ“ˆ Best Validation Accuracy: {trainer.best_val_accuracy:.2f}%")
    print(f"ðŸ”¥ Final Training Accuracy: {history['train_accuracy'][-1]:.2f}%")
    print(f"âœ… Final Validation Accuracy: {history['val_accuracy'][-1]:.2f}%")
    print(f"ðŸ“¦ Model saved to: {model_path}")
    print("="*80)
    
    return model, history, class_to_idx, device

def evaluate_model(model_path, config, logger):
    """Evaluate a trained model."""
    logger.info(f"Evaluating model from {model_path}...")
    
    # Setup device
    device = DeviceManager.get_device(config)
    
    # Create data loaders
    _, test_loader, class_to_idx = create_data_loaders(config)
    logger.info(f"Loaded test data with {len(class_to_idx)} classes")
    
    # Create and load model
    model = create_model_from_config(config)
    trainer = Trainer(model, config, device)
    trainer.load_model(model_path, load_optimizer=False)
    
    # Evaluate model
    evaluator = ModelEvaluator(model, class_to_idx, config)
    results = evaluator.evaluate(test_loader, device)
    
    # Print summary
    evaluator.print_summary()
    
    return results, class_to_idx, test_loader

def run_hyperparameter_search(config, max_experiments, logger):
    """Run hyperparameter analysis."""
    logger.info("Starting hyperparameter search...")
    
    # Create analyzer
    analyzer = HyperparameterAnalyzer(config, exclude_optimal=True)
    
    # Run grid search
    results = analyzer.run_grid_search(max_experiments)
    
    # Analyze results
    analysis = analyzer.analyze_results()
    
    # Generate report
    report = analyzer.create_hyperparameter_report()
    print(report)
    
    # Save report
    report_file = os.path.join(config.get('hyperparameter_analysis.results_dir', 'results/hyperparameter_analysis'), 
                               'hyperparameter_report.txt')
    with open(report_file, 'w') as f:
        f.write(report)
    
    logger.info(f"Hyperparameter analysis completed. Report saved to {report_file}")
    
    return analysis

def create_visualizations(model, history, evaluation_results, class_to_idx, test_loader, device, config, logger):
    """Create comprehensive visualizations."""
    logger.info("Creating visualizations...")
    
    # Create visualizer
    visualizer = Visualizer(config)
    
    # Get class names
    class_names = list(class_to_idx.keys())
    
    # Create comprehensive report
    visualizer.create_comprehensive_report(history, evaluation_results, class_names, test_loader, model, device)
    
    # Save metrics summary
    visualizer.save_metrics_summary(history, evaluation_results)
    
    logger.info("Visualizations completed")

def main():
    """Main function."""
    parser = argparse.ArgumentParser(description='CNN Visual Object Classification')
    parser.add_argument('--mode', choices=['train', 'evaluate', 'hyperparameter_search', 'full_pipeline'],
                       required=True, help='Mode to run')
    parser.add_argument('--config', default='config.yaml', help='Path to configuration file')
    parser.add_argument('--model_path', default='models/best_model.pth', help='Path to trained model')
    parser.add_argument('--max_experiments', type=int, default=None, 
                       help='Maximum number of experiments for hyperparameter search')
    
    args = parser.parse_args()
    
    # Load configuration
    try:
        config = ConfigManager(args.config)
    except Exception as e:
        print(f"Error loading configuration: {e}")
        sys.exit(1)
    
    # Setup logging
    logger = setup_logging(config)
    logger.info(f"Starting CNN pipeline in mode: {args.mode}")
    logger.info(f"Configuration loaded from: {args.config}")
    
    try:
        if args.mode == 'train':
            # Train model
            model, history, class_to_idx, device = train_model(config, logger)
            logger.info("Training completed successfully!")
            
        elif args.mode == 'evaluate':
            # Evaluate model
            if not os.path.exists(args.model_path):
                logger.error(f"Model file not found: {args.model_path}")
                sys.exit(1)
            
            evaluation_results, class_to_idx, test_loader = evaluate_model(args.model_path, config, logger)
            
            # Create visualizations
            if config.get('visualization.save_plots', True):
                # Load model for visualization
                device = DeviceManager.get_device(config)
                model = create_model_from_config(config)
                trainer = Trainer(model, config, device)
                trainer.load_model(args.model_path, load_optimizer=False)
                
                # Load actual training history from saved model
                checkpoint = torch.load(args.model_path, map_location='cpu')
                history = checkpoint.get('history', {
                    'train_loss': [0.5],
                    'val_loss': [0.4],
                    'train_accuracy': [80.0],
                    'val_accuracy': [78.0],
                    'learning_rates': [0.001]
                })
                
                create_visualizations(model, history, evaluation_results, class_to_idx, 
                                    test_loader, device, config, logger)
            
            logger.info("Evaluation completed successfully!")
            
        elif args.mode == 'hyperparameter_search':
            # Run hyperparameter search
            if not config.get('hyperparameter_analysis.enabled', False):
                logger.error("Hyperparameter analysis is disabled in configuration")
                sys.exit(1)
            
            analysis = run_hyperparameter_search(config, args.max_experiments, logger)
            logger.info("Hyperparameter search completed successfully!")
            
        elif args.mode == 'full_pipeline':
            # Run complete pipeline: train -> evaluate -> visualize
            logger.info("Running complete pipeline...")
            
            # 1. Train model
            model, history, class_to_idx, device = train_model(config, logger)
            
            # 2. Evaluate model
            model_path = os.path.join(config.get('logging.model_save_dir', 'models'), 'best_model.pth')
            evaluation_results, _, test_loader = evaluate_model(model_path, config, logger)
            
            # 3. Create visualizations
            create_visualizations(model, history, evaluation_results, class_to_idx, 
                                test_loader, device, config, logger)
            
            # 4. Run hyperparameter analysis if enabled
            if config.get('hyperparameter_analysis.enabled', False):
                logger.info("Running hyperparameter analysis...")
                analysis = run_hyperparameter_search(config, args.max_experiments, logger)
            
            logger.info("Full pipeline completed successfully!")
    
    except KeyboardInterrupt:
        logger.info("Pipeline interrupted by user")
        sys.exit(0)
    except Exception as e:
        logger.error(f"Pipeline failed: {str(e)}")
        raise

if __name__ == "__main__":
    main()
